{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **INSTALAÇÃO DE REQUERIMENTOS**"
      ],
      "metadata": {
        "id": "EHSZlyvhmcOe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MO67K-wIfoZ",
        "outputId": "999b918e-3380-4012-ac03-47319b34250f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dust3r'...\n",
            "remote: Enumerating objects: 154, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 154 (delta 40), reused 29 (delta 29), pack-reused 89\u001b[K\n",
            "Receiving objects: 100% (154/154), 587.68 KiB | 2.02 MiB/s, done.\n",
            "Resolving deltas: 100% (61/61), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/saulocatharino/dust3r.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozCkiE3FIq1r",
        "outputId": "1c404bd9-569a-4c0f-a2cb-95bc71cc7835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dust3r\n"
          ]
        }
      ],
      "source": [
        "%cd /content/dust3r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGuXzGJNrezn",
        "outputId": "ce244671-d922-4fa2-e8fb-c749da8c8a4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submodule 'croco' (https://github.com/naver/croco) registered for path 'croco'\n",
            "Cloning into '/content/dust3r/croco'...\n",
            "Submodule path 'croco': checked out '743ee71a2a9bf57cea6832a9064a70a0597fcfcb'\n"
          ]
        }
      ],
      "source": [
        "!git submodule update --init --recursive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaP139BGKb2L",
        "outputId": "8f260b8d-47d8-4b36-e5ea-c2a10a46c422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-16 23:34:04--  https://download.europe.naverlabs.com/ComputerVision/DUSt3R/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\n",
            "Resolving download.europe.naverlabs.com (download.europe.naverlabs.com)... 110.234.56.25\n",
            "Connecting to download.europe.naverlabs.com (download.europe.naverlabs.com)|110.234.56.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2285019929 (2.1G)\n",
            "Saving to: ‘checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth’\n",
            "\n",
            "DUSt3R_ViTLarge_Bas 100%[===================>]   2.13G  19.0MB/s    in 1m 59s  \n",
            "\n",
            "2024-04-16 23:36:04 (18.3 MB/s) - ‘checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth’ saved [2285019929/2285019929]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p checkpoints/\n",
        "!wget https://download.europe.naverlabs.com/ComputerVision/DUSt3R/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth -P checkpoints/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IklSuBfGYzgO",
        "outputId": "8b9ac32b-a81d-4dbc-9d15-82b0331d47bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dust3r/croco/models/curope\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:500: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:415: UserWarning: The detected CUDA version (12.2) has a minor version mismatch with the version that was used to compile PyTorch (12.1). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:425: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.2\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building 'curope' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c curope.cpp -o build/temp.linux-x86_64-cpython-310/curope.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=curope -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c kernels.cu -o build/temp.linux-x86_64-cpython-310/kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --ptxas-options=-v --use_fast_math -gencode arch=compute_50,code=sm_50 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=curope -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "ptxas info    : 3 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff' for 'sm_50'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 28 registers, 376 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_50'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 29 registers, 376 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_50'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 30 registers, 376 bytes cmem[0], 8 bytes cmem[2]\n",
            "ptxas info    : 3 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff' for 'sm_60'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 28 registers, 376 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_60'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 29 registers, 376 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_60'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 28 registers, 376 bytes cmem[0], 8 bytes cmem[2]\n",
            "ptxas info    : 3 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 30 registers, 408 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 32 registers, 408 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 30 registers, 408 bytes cmem[0], 8 bytes cmem[2]\n",
            "ptxas info    : 3 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff' for 'sm_75'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 29 registers, 408 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_75'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 30 registers, 408 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_75'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 32 registers, 408 bytes cmem[0], 8 bytes cmem[2]\n",
            "ptxas info    : 3 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff' for 'sm_80'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 26 registers, 408 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_80'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 30 registers, 408 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_80'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 30 registers, 408 bytes cmem[0], 8 bytes cmem[2]\n",
            "ptxas info    : 3 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff' for 'sm_86'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 27 registers, 408 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_86'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 30 registers, 408 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_86'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 32 registers, 408 bytes cmem[0], 8 bytes cmem[2]\n",
            "ptxas info    : 3 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff' for 'sm_90'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 26 registers\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_90'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 32 registers\n",
            "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_90'\n",
            "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 30 registers\n",
            "\u001b[01m\u001b[Kkernels.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kkernels.cu:101:43:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  101 |     AT_DISPATCH_FLOATING_TYPE\u001b[01;35m\u001b[KS_AND_HALF(toke\u001b[m\u001b[Kns.type(), \"rope_2d_cuda\", ([&] {\n",
            "      |                              \u001b[01;35m\u001b[K~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkernels.cu:101:149:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  101 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(tokens.type(), \"rope_2d_cuda\", ([&] {\n",
            "      |                                                                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K         \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:109:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  109 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/curope.o build/temp.linux-x86_64-cpython-310/kernels.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/curope.cpython-310-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-cpython-310/curope.cpython-310-x86_64-linux-gnu.so -> \n",
            "/content/dust3r\n"
          ]
        }
      ],
      "source": [
        "# DUST3R relies on RoPE positional embeddings for which you can compile some cuda kernels for faster runtime.\n",
        "%cd croco/models/curope/\n",
        "!python setup.py build_ext --inplace\n",
        "%cd ../../../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Aq5oGHlWxUeM",
        "outputId": "52e6c686-8df2-404f-c649-f9619100ebc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow-heif (from -r requirements_optional.txt (line 1))\n",
            "  Downloading pillow_heif-0.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow>=9.5.0 (from pillow-heif->-r requirements_optional.txt (line 1))\n",
            "  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow, pillow-heif\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pillow-10.3.0 pillow-heif-0.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "1adc384a4766479ea31aac5c6509798a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements_optional.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT0GeXcAVqHr",
        "outputId": "5288b88c-95b0-418a-856a-20bdd702291b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dust3r\n"
          ]
        }
      ],
      "source": [
        "%cd /content/dust3r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8Q63xvNxixZ",
        "outputId": "385bcf01-adc1-4ae7-8b8f-a60ffcd09710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.17.1+cu121)\n",
            "Collecting roma (from -r requirements.txt (line 3))\n",
            "  Downloading roma-1.4.5-py3-none-any.whl (21 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 4))\n",
            "  Downloading gradio-4.26.0-py3-none-any.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.66.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.8.0.76)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.11.4)\n",
            "Collecting einops (from -r requirements.txt (line 9))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trimesh (from -r requirements.txt (line 10))\n",
            "  Downloading trimesh-4.3.1-py3-none-any.whl (693 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.8/693.8 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.15.2)\n",
            "Collecting pyglet<2 (from -r requirements.txt (line 12))\n",
            "  Downloading pyglet-1.5.28-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (10.3.0)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (4.2.2)\n",
            "Collecting fastapi (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading fastapi-0.110.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.15.1 (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading gradio_client-0.15.1-py3-none-any.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (6.4.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (2.1.5)\n",
            "Collecting orjson~=3.0 (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (2.0.3)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (2.6.4)\n",
            "Collecting pydub (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading ruff-0.3.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (0.9.4)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio-client==0.15.1->gradio->-r requirements.txt (line 4))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.62.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (3.0.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 4)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 4)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 11)) (1.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 4)) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio->-r requirements.txt (line 4))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 4)) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 4)) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 4))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 4)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 4)) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 4)) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 11)) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 11)) (2.0.7)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 4)) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 4))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 4))\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 4)) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio->-r requirements.txt (line 4))\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 4)) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 4)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 4)) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 4)) (0.18.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 11)) (3.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 4)) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 4)) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=69e282847508c671222c58ef907038f546a4f7f5a818f67cd1f293ea25d9561b\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pyglet, pydub, ffmpy, websockets, trimesh, tomlkit, shellingham, semantic-version, ruff, roma, python-multipart, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, h11, einops, colorama, aiofiles, uvicorn, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, httpcore, nvidia-cusolver-cu12, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.2.1 colorama-0.4.6 einops-0.7.0 fastapi-0.110.1 ffmpy-0.3.2 gradio-4.26.0 gradio-client-0.15.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 orjson-3.10.1 pydub-0.25.1 pyglet-1.5.28 python-multipart-0.0.9 roma-1.4.5 ruff-0.3.7 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 trimesh-4.3.1 uvicorn-0.29.0 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guTsKeHwJW-r"
      },
      "source": [
        "## **EXPORTA MODELO 3D**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS-1CPrJT4wc",
        "outputId": "a3a983d7-094c-42a7-ede4-6e1388be87b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dust3r\n",
            "... loading model from checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\n",
            "instantiating : AsymmetricCroCo3DStereo(enc_depth=24, dec_depth=12, enc_embed_dim=1024, dec_embed_dim=768, enc_num_heads=16, dec_num_heads=12, pos_embed='RoPE100', patch_embed_cls='PatchEmbedDust3R', img_size=(512, 512), head_type='dpt', output_mode='pts3d', depth_mode=('exp', -inf, inf), conf_mode=('exp', 1, inf), landscape_only=False)\n",
            "<All keys matched successfully>\n",
            ">> Loading images from sala\n",
            " - adding IMG-20240416-WA0007.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0008.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0009.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0010.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0012.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0013.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0016.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0017.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0018.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0019.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0020.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0021.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0022.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0023.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0024.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0025.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0026.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0027.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0028.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0029.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0030.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0031.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0032.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0033.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0034.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding IMG-20240416-WA0035.jpg with resolution 1600x1200 --> 512x384\n",
            " (Found 26 images)\n",
            ">> Inference with model on 208 image pairs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [02:18<00:00,  5.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " init edge (13*,14*) score=189.3213653564453\n",
            " init edge (13,10*) score=77.46690368652344\n",
            " init edge (14,16*) score=58.00434875488281\n",
            " init edge (19*,16) score=10.265995025634766\n",
            " init edge (15*,13) score=6.484203338623047\n",
            " init edge (20*,19) score=5.9479756355285645\n",
            " init edge (10,7*) score=2.7390027046203613\n",
            " init edge (20,18*) score=2.4757490158081055\n",
            " init edge (19,21*) score=132.26380920410156\n",
            " init edge (22*,21) score=46.69668197631836\n",
            " init edge (7,6*) score=24.63801383972168\n",
            " init edge (22,24*) score=20.064966201782227\n",
            " init edge (7,4*) score=15.021427154541016\n",
            " init edge (23*,22) score=9.625177383422852\n",
            " init edge (20,17*) score=7.667440891265869\n",
            " init edge (8*,6) score=37.21819305419922\n",
            " init edge (25*,23) score=18.31930923461914\n",
            " init edge (8,5*) score=13.921257019042969\n",
            " init edge (11*,8) score=3.011971950531006\n",
            " init edge (25,0*) score=32.65842056274414\n",
            " init edge (3*,0) score=29.032541275024414\n",
            " init edge (2*,3) score=26.897125244140625\n",
            " init edge (9*,11) score=9.631421089172363\n",
            " init edge (9,12*) score=5.813579559326172\n",
            " init edge (2,1*) score=3.274186134338379\n",
            " init loss = 0.020736008882522583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [02:06<00:00,  2.37it/s, lr=1.27413e-06 loss=0.00361034]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(exporting 3D scene to sala.glb )\n"
          ]
        }
      ],
      "source": [
        "%cd /content/dust3r\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import trimesh\n",
        "import copy\n",
        "from scipy.spatial.transform import Rotation\n",
        "from dust3r.inference import inference, load_model\n",
        "from dust3r.image_pairs import make_pairs\n",
        "from dust3r.utils.image import load_images, rgb\n",
        "from dust3r.utils.device import to_numpy\n",
        "from dust3r.viz import add_scene_cam, CAM_COLORS, OPENGL, pts3d_to_trimesh, cat_meshes\n",
        "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
        "\n",
        "def convert_scene_output_to_glb(outdir, imgs, pts3d, mask, focals, cams2world, output_file, cam_size=0.05,\n",
        "                                cam_color=None, as_pointcloud=False,\n",
        "                                transparent_cams=False, silent=False):\n",
        "    assert len(pts3d) == len(mask) <= len(imgs) <= len(cams2world) == len(focals)\n",
        "    pts3d = to_numpy(pts3d)\n",
        "    imgs = to_numpy(imgs)\n",
        "    focals = to_numpy(focals)\n",
        "    cams2world = to_numpy(cams2world)\n",
        "\n",
        "    scene = trimesh.Scene()\n",
        "\n",
        "    # Full pointcloud or mesh\n",
        "    if as_pointcloud:\n",
        "        pts = np.concatenate([p[m] for p, m in zip(pts3d, mask)])\n",
        "        col = np.concatenate([p[m] for p, m in zip(imgs, mask)])\n",
        "        pct = trimesh.PointCloud(pts.reshape(-1, 3), colors=col.reshape(-1, 3))\n",
        "        scene.add_geometry(pct)\n",
        "    else:\n",
        "        meshes = []\n",
        "        for i in range(len(imgs)):\n",
        "            meshes.append(pts3d_to_trimesh(imgs[i], pts3d[i], mask[i]))\n",
        "        mesh = trimesh.Trimesh(**cat_meshes(meshes))\n",
        "        scene.add_geometry(mesh)\n",
        "\n",
        "    # Add each camera\n",
        "    for i, pose_c2w in enumerate(cams2world):\n",
        "        camera_edge_color = cam_color[i % len(cam_color)] if isinstance(cam_color, list) else cam_color or CAM_COLORS[i % len(CAM_COLORS)]\n",
        "        add_scene_cam(scene, pose_c2w, camera_edge_color,\n",
        "                      None if transparent_cams else imgs[i], focals[i],\n",
        "                      imsize=imgs[i].shape[1::-1], screen_width=cam_size)\n",
        "\n",
        "    # Apply transformation and export GLB file\n",
        "    rot = np.eye(4)\n",
        "    rot[:3, :3] = Rotation.from_euler('y', np.deg2rad(180)).as_matrix()\n",
        "    scene.apply_transform(np.linalg.inv(cams2world[0] @ OPENGL @ rot))\n",
        "    outfile = os.path.join(outdir, output_file)\n",
        "    if not silent:\n",
        "        print('(exporting 3D scene to', outfile, ')')\n",
        "    scene.export(file_obj=outfile)\n",
        "    return outfile\n",
        "\n",
        "def get_3D_model_from_scene(outdir, silent, scene, output_file, min_conf_thr=3, as_pointcloud=False, mask_sky=True,\n",
        "                            clean_depth=True, transparent_cams=True, cam_size=0.00):\n",
        "    if scene is None:\n",
        "        return None\n",
        "\n",
        "    # Post-processing\n",
        "    if clean_depth:\n",
        "        scene = scene.clean_pointcloud()\n",
        "    if mask_sky:\n",
        "        scene = scene.mask_sky()\n",
        "\n",
        "    # Get optimized values from scene\n",
        "    rgbimg = scene.imgs\n",
        "    focals = scene.get_focals().cpu()\n",
        "    cams2world = scene.get_im_poses().cpu()\n",
        "    pts3d = to_numpy(scene.get_pts3d())\n",
        "    scene.min_conf_thr = float(scene.conf_trf(torch.tensor(min_conf_thr)))\n",
        "    msk = to_numpy(scene.get_masks())\n",
        "    return convert_scene_output_to_glb(outdir, rgbimg, pts3d, msk, focals, cams2world, output_file, as_pointcloud=as_pointcloud,\n",
        "                                       transparent_cams=transparent_cams, cam_size=cam_size, silent=silent)\n",
        "\n",
        "def main(weights_path, image_folder, output_file):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = load_model(weights_path, device=device)\n",
        "\n",
        "    imgs = load_images(image_folder, size=512)\n",
        "    if len(imgs) == 1:\n",
        "        imgs = [imgs[0], copy.deepcopy(imgs[0])]\n",
        "        imgs[1]['idx'] = 1\n",
        "\n",
        "    tam = len(imgs)-1\n",
        "\n",
        "    scenegraph_type = f\"swin-4\"\n",
        "    #scenegraph_type = f\"oneref-{tam}\"\n",
        "\n",
        "    pairs = make_pairs(imgs, scene_graph=scenegraph_type, prefilter=None, symmetrize=True)\n",
        "    output = inference(pairs, model, device)\n",
        "\n",
        "    mode = GlobalAlignerMode.PointCloudOptimizer if len(imgs) > 2 else GlobalAlignerMode.PairViewer\n",
        "    scene = global_aligner(output, device=device, mode=mode)\n",
        "\n",
        "    if mode == GlobalAlignerMode.PointCloudOptimizer:\n",
        "        loss = scene.compute_global_alignment(init='mst')\n",
        "\n",
        "    outfile = get_3D_model_from_scene('', False, scene, output_file)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    weights_path = \"checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\"\n",
        "    image_folder = \"sala\"\n",
        "    output_file = \"sala.glb\"\n",
        "    main(weights_path, image_folder, output_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qda1QwD5JhXg"
      },
      "source": [
        "## **EXPORTAR DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DYu4JtjkW8n"
      },
      "outputs": [],
      "source": [
        "%cd /content/dust3r\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import trimesh\n",
        "import copy\n",
        "from scipy.spatial.transform import Rotation\n",
        "from dust3r.inference import inference, load_model\n",
        "from dust3r.image_pairs import make_pairs\n",
        "from dust3r.utils.image import load_images, rgb\n",
        "from dust3r.utils.device import to_numpy\n",
        "from dust3r.viz import add_scene_cam, CAM_COLORS, OPENGL, pts3d_to_trimesh, cat_meshes\n",
        "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import glob\n",
        "\n",
        "def convert_scene_output_to_glb(outdir, imgs, pts3d, mask, focals, cams2world, output_file, cam_size=0.05,\n",
        "                                cam_color=None, as_pointcloud=False,\n",
        "                                transparent_cams=False, silent=False):\n",
        "    assert len(pts3d) == len(mask) <= len(imgs) <= len(cams2world) == len(focals)\n",
        "    pts3d = to_numpy(pts3d)\n",
        "    imgs = to_numpy(imgs)\n",
        "    focals = to_numpy(focals)\n",
        "    cams2world = to_numpy(cams2world)\n",
        "\n",
        "    scene = trimesh.Scene()\n",
        "\n",
        "    # Full pointcloud or mesh\n",
        "    if as_pointcloud:\n",
        "        pts = np.concatenate([p[m] for p, m in zip(pts3d, mask)])\n",
        "        col = np.concatenate([p[m] for p, m in zip(imgs, mask)])\n",
        "        pct = trimesh.PointCloud(pts.reshape(-1, 3), colors=col.reshape(-1, 3))\n",
        "        scene.add_geometry(pct)\n",
        "    else:\n",
        "        meshes = []\n",
        "        for i in range(len(imgs)):\n",
        "            meshes.append(pts3d_to_trimesh(imgs[i], pts3d[i], mask[i]))\n",
        "        mesh = trimesh.Trimesh(**cat_meshes(meshes))\n",
        "        scene.add_geometry(mesh)\n",
        "\n",
        "    # Add each camera\n",
        "    for i, pose_c2w in enumerate(cams2world):\n",
        "        camera_edge_color = cam_color[i % len(cam_color)] if isinstance(cam_color, list) else cam_color or CAM_COLORS[i % len(CAM_COLORS)]\n",
        "        add_scene_cam(scene, pose_c2w, camera_edge_color,\n",
        "                      None if transparent_cams else imgs[i], focals[i],\n",
        "                      imsize=imgs[i].shape[1::-1], screen_width=cam_size)\n",
        "\n",
        "    # Apply transformation and export GLB file\n",
        "    rot = np.eye(4)\n",
        "    rot[:3, :3] = Rotation.from_euler('y', np.deg2rad(180)).as_matrix()\n",
        "    scene.apply_transform(np.linalg.inv(cams2world[0] @ OPENGL @ rot))\n",
        "    outfile = os.path.join(outdir, output_file)\n",
        "    if not silent:\n",
        "        print('(exporting 3D scene to', outfile, ')')\n",
        "    scene.export(file_obj=outfile)\n",
        "    return outfile\n",
        "\n",
        "def get_3D_model_from_scene(outdir, silent, scene, output_file, min_conf_thr=3, as_pointcloud=False, mask_sky=True,\n",
        "                            clean_depth=True, transparent_cams=True, cam_size=0.00):\n",
        "    if scene is None:\n",
        "        return None\n",
        "\n",
        "    # Post-processing\n",
        "    if clean_depth:\n",
        "        scene = scene.clean_pointcloud()\n",
        "    if mask_sky:\n",
        "        scene = scene.mask_sky()\n",
        "\n",
        "    # Get optimized values from scene\n",
        "    rgbimg = scene.imgs\n",
        "    focals = scene.get_focals().cpu()\n",
        "    cams2world = scene.get_im_poses().cpu()\n",
        "    pts3d = to_numpy(scene.get_pts3d())\n",
        "    scene.min_conf_thr = float(scene.conf_trf(torch.tensor(min_conf_thr)))\n",
        "    msk = to_numpy(scene.get_masks())\n",
        "    return convert_scene_output_to_glb(outdir, rgbimg, pts3d, msk, focals, cams2world, output_file, as_pointcloud=as_pointcloud,\n",
        "                                       transparent_cams=transparent_cams, cam_size=cam_size, silent=silent)\n",
        "\n",
        "def main(weights_path, image_folder, output_folder, output_file=\"modelo.glb\"):\n",
        "    i = 1\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = load_model(weights_path, device=device)\n",
        "\n",
        "    im_fold_tem = glob.glob(f\"{image_folder}/*.png\")\n",
        "    for im in im_fold_tem:\n",
        "      os.system(f\"cp {im} temp_img/1.png\")\n",
        "      imgs = load_images('temp_img', size=512)\n",
        "      if len(imgs) == 1:\n",
        "          imgs = [imgs[0], copy.deepcopy(imgs[0])]\n",
        "          imgs[1]['idx'] = 1\n",
        "\n",
        "      print(imgs[0].keys())\n",
        "      tam = len(imgs)-1\n",
        "\n",
        "      scenegraph_type = f\"swin-{tam}\"\n",
        "      #scenegraph_type = f\"oneref-{tam}\"\n",
        "\n",
        "      pairs = make_pairs(imgs, scene_graph=scenegraph_type, prefilter=None, symmetrize=True)\n",
        "      output = inference(pairs, model, device)\n",
        "\n",
        "      mode = GlobalAlignerMode.PointCloudOptimizer if len(imgs) > 2 else GlobalAlignerMode.PairViewer\n",
        "      scene = global_aligner(output, device=device, mode=mode)\n",
        "\n",
        "      if mode == GlobalAlignerMode.PointCloudOptimizer:\n",
        "          loss = scene.compute_global_alignment(init='mst')\n",
        "\n",
        "      pts3d = to_numpy(scene.get_pts3d())\n",
        "\n",
        "      for pts in pts3d:\n",
        "        normalizedpts3d = cv2.normalize(pts,  pts, 0, 255, cv2.NORM_MINMAX)\n",
        "        one_channel_3d = cv2.cvtColor(normalizedpts3d, cv2.COLOR_BGR2GRAY)\n",
        "        cv2_imshow(one_channel_3d)\n",
        "        cv2.imwrite(f\"{output_folder}/{i}.jpg\", one_channel_3d)\n",
        "        print(f\"Imagem convertida e salva em {output_folder}/{i}.jpg\")\n",
        "        i += 1\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    weights_path = \"checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\"\n",
        "    image_folder = \"dataset_top\"\n",
        "    output_folder = 'output3d_top'\n",
        "    main(weights_path, image_folder, output_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yowAbohiJPPc"
      },
      "outputs": [],
      "source": [
        "%cd /content/dust3r\n",
        "!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s-seg.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMG90YvPK6qJ"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics==8.0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-JHGUUVVmiG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOSarZFBc300"
      },
      "outputs": [],
      "source": [
        "%cd /content/dust3r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGkuhh0NVvza"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/engord.ai/estimativa_de_peso_vivo_03.keras ./\n",
        "!cp /content/drive/MyDrive/engord.ai/dataset.csv ./\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghMCcpSfCwUu"
      },
      "source": [
        "## **INFERÊNCIA PESO GADO (sem streamlit)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2cpDV3Gbq0B"
      },
      "outputs": [],
      "source": [
        "%cd /content/dust3r\n",
        "import torch\n",
        "import numpy as np\n",
        "import copy\n",
        "from dust3r.inference import inference, load_model\n",
        "from dust3r.image_pairs import make_pairs\n",
        "from dust3r.utils.image import load_images\n",
        "from dust3r.utils.device import to_numpy\n",
        "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "import pandas as pd\n",
        "\n",
        "weights_path = \"checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\"\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def create_model():\n",
        "  campos= ['live weithg', 'withers height', 'hip height', 'chest depth', 'chest width', 'ilium width', 'hip joint width', 'oblique body length', 'hip length', 'heart girth']\n",
        "\n",
        "  dim = 256\n",
        "  input_shape = (dim, dim, 1)\n",
        "\n",
        "  # Crie duas entradas separadas\n",
        "  depth_input_1 = Input(shape=input_shape, name='depth_input_1')\n",
        "  depth_input_2 = Input(shape=input_shape, name='depth_input_2')\n",
        "\n",
        "  # Continue com a arquitetura da sua rede\n",
        "  x1 = Conv2D(64, (3, 3), activation='relu')(depth_input_1)\n",
        "  x1 = MaxPooling2D((2, 2))(x1)\n",
        "  x1 = Conv2D(128, (3, 3), activation='relu')(x1)\n",
        "  x1 = MaxPooling2D((2, 2))(x1)\n",
        "  x1 = Conv2D(256, (3, 3), activation='relu')(x1)\n",
        "  x1 = MaxPooling2D((2, 2))(x1)\n",
        "  x1 = Flatten()(x1)\n",
        "\n",
        "  x2 = Conv2D(64, (3, 3), activation='relu')(depth_input_2)\n",
        "  x2 = MaxPooling2D((2, 2))(x2)\n",
        "  x2 = Conv2D(128, (3, 3), activation='relu')(x2)\n",
        "  x2 = MaxPooling2D((2, 2))(x2)\n",
        "  x2 = Conv2D(256, (3, 3), activation='relu')(x2)\n",
        "  x2 = MaxPooling2D((2, 2))(x2)\n",
        "  x2 = Flatten()(x2)\n",
        "\n",
        "  # Concatene as saídas das camadas convolucionais\n",
        "  concatenated_output = Concatenate()([x1, x2])\n",
        "\n",
        "  x = Dense(256, activation='relu')(concatenated_output)\n",
        "\n",
        "  # Saída\n",
        "  output = Dense(len(campos), activation='linear')(x)\n",
        "\n",
        "  # Construa o modelo com as duas entradas\n",
        "  model = Model(inputs=[depth_input_1, depth_input_2], outputs=output)\n",
        "\n",
        "  # Compile o modelo\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "  return model\n",
        "\n",
        "inference_model = create_model()\n",
        "inference_model.load_weights(\"estimativa_de_peso_vivo_03.keras\")\n",
        "model = load_model(weights_path, device=device)\n",
        "model_seg = YOLO('yolov8s-seg.pt')\n",
        "\n",
        "# Carregando o CSV com os dados\n",
        "data = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Dicionário de tradução das saídas\n",
        "traducao = {\n",
        "    'live weithg': 'Peso Vivo',\n",
        "    'withers height': 'Altura da Cernelha',\n",
        "    'hip height': 'Altura do Quadril',\n",
        "    'chest depth': 'Profundidade do Peito',\n",
        "    'chest width': 'Largura do Peito',\n",
        "    'ilium width': 'Largura do Ílio',\n",
        "    'hip joint width': 'Largura da Articulação do Quadril',\n",
        "    'oblique body length': 'Comprimento do Corpo Oblíquo',\n",
        "    'hip length': 'Comprimento do Quadril',\n",
        "    'heart girth': 'Circunferência Torácica'\n",
        "}\n",
        "\n",
        "\n",
        "def get_depth(image):\n",
        "    depths = []\n",
        "    i = 1\n",
        "    cv2.imwrite('/content/dust3r/temp_img/1.png',image)\n",
        "    imgs = load_images('/content/dust3r/temp_img', size=512)\n",
        "    if len(imgs) == 1:\n",
        "        imgs = [imgs[0], copy.deepcopy(imgs[0])]\n",
        "        imgs[1]['idx'] = 1\n",
        "\n",
        "    scenegraph_type = f\"swin-1\"\n",
        "\n",
        "    pairs = make_pairs(imgs, scene_graph=scenegraph_type, prefilter=None, symmetrize=True)\n",
        "    output = inference(pairs, model, device)\n",
        "\n",
        "    mode = GlobalAlignerMode.PointCloudOptimizer if len(imgs) > 2 else GlobalAlignerMode.PairViewer\n",
        "    scene = global_aligner(output, device=device, mode=mode)\n",
        "\n",
        "    if mode == GlobalAlignerMode.PointCloudOptimizer:\n",
        "        loss = scene.compute_global_alignment(init='mst')\n",
        "\n",
        "    pts3d = to_numpy(scene.get_pts3d())\n",
        "\n",
        "    for pts in pts3d:\n",
        "      normalizedpts3d = cv2.normalize(pts,  pts, 0, 255, cv2.NORM_MINMAX)\n",
        "      one_channel_3d = cv2.cvtColor(normalizedpts3d, cv2.COLOR_BGR2GRAY)\n",
        "      one_channel_3d = cv2.resize(one_channel_3d, (256,256))\n",
        "      depths.append(one_channel_3d)\n",
        "      print(f\"Imagem convertida {i}\")\n",
        "      i += 1\n",
        "    return depths\n",
        "\n",
        "def get_mask(image):\n",
        "  results = model_seg.predict(image.copy(), conf=0.40)\n",
        "  masks = results[0].masks\n",
        "  mask1 = masks.masks\n",
        "  mask = mask1.data.cpu().numpy()\n",
        "  mask = mask.squeeze()\n",
        "  return mask\n",
        "\n",
        "\n",
        "\n",
        "dim = 256\n",
        "name_file = '20.png'\n",
        "image = cv2.imread(name_file)\n",
        "\n",
        "\n",
        "fig0, ax0 = plt.subplots()\n",
        "ax0.imshow(image)\n",
        "\n",
        "depths = get_depth(image)\n",
        "depth = depths[0]\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.imshow(depth)\n",
        "\n",
        "\n",
        "\n",
        "mask = get_mask(image)\n",
        "\n",
        "\n",
        "resize_depth = cv2.resize(depth,(dim,dim))\n",
        "norm_depth = resize_depth / 255.\n",
        "\n",
        "depth_fim = np.expand_dims(norm_depth, axis=0)\n",
        "mask_fim = cv2.resize(mask,(256,256))\n",
        "fig2, ax2 = plt.subplots()\n",
        "ax2.imshow(mask_fim)\n",
        "\n",
        "plt.show()\n",
        "mask_fim = np.expand_dims(mask_fim, axis=0)\n",
        "prediction = inference_model.predict([depth_fim, mask_fim])\n",
        "\n",
        "\n",
        "predictions = []\n",
        "try:\n",
        "    print(\"---------------------\")\n",
        "    print(\"PREDIÇÕES\")\n",
        "    for i, campo in enumerate(traducao.keys()):\n",
        "        print(f'{traducao[campo]}: {round(float(prediction[0][i]),2)}')\n",
        "        predictions.append(prediction[0][i])\n",
        "\n",
        "except:\n",
        "    pass\n",
        "\n",
        "N = int(name_file.split(\".\")[0])\n",
        "precisao_total = []\n",
        "print(\"---------------------\")\n",
        "print(\"DADOS REAIS\")\n",
        "for i,campo in enumerate(traducao.keys()):\n",
        "    if campo == \"N\" or 'time' in campo or 'Data' in campo:\n",
        "        continue\n",
        "    v = float(data.iloc[N][campo])\n",
        "    p = predictions[i]\n",
        "    per = v/ 100\n",
        "    diff = abs(v-p)\n",
        "    percent = 100 - (diff/per)\n",
        "    precisao_total.append(percent)\n",
        "    print(f'{traducao[campo]}: {data.iloc[N][campo]}', f' (Precisão: {round(percent,2)}%)')\n",
        "\n",
        "precisao_modelo = sum(precisao_total)/len(precisao_total)\n",
        "print('-----------------')\n",
        "print(f\"Precisão do Modelo: {round(precisao_modelo,2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **INFERENCIA PESO GADO (com streamlit)**\n"
      ],
      "metadata": {
        "id": "d1KazOpv2v9W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kb2udm3-CrLC"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6OKrwO4C-TY"
      },
      "outputs": [],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/dust3r"
      ],
      "metadata": {
        "id": "ScPqGV4RrEdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCL1IUT2CnKZ"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "import numpy as np\n",
        "import copy\n",
        "from dust3r.inference import inference, load_model\n",
        "from dust3r.image_pairs import make_pairs\n",
        "from dust3r.utils.image import load_images\n",
        "from dust3r.utils.device import to_numpy\n",
        "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "import pandas as pd\n",
        "\n",
        "st.set_page_config(layout=\"wide\")\n",
        "\n",
        "weights_path = \"checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\"\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def create_model():\n",
        "  campos= ['live weithg', 'withers height', 'hip height', 'chest depth', 'chest width', 'ilium width', 'hip joint width', 'oblique body length', 'hip length', 'heart girth']\n",
        "\n",
        "  dim = 256\n",
        "  input_shape = (dim, dim, 1)\n",
        "\n",
        "  # Crie duas entradas separadas\n",
        "  depth_input_1 = Input(shape=input_shape, name='depth_input_1')\n",
        "  depth_input_2 = Input(shape=input_shape, name='depth_input_2')\n",
        "\n",
        "  # Continue com a arquitetura da sua rede\n",
        "  x1 = Conv2D(64, (3, 3), activation='relu')(depth_input_1)\n",
        "  x1 = MaxPooling2D((2, 2))(x1)\n",
        "  x1 = Conv2D(128, (3, 3), activation='relu')(x1)\n",
        "  x1 = MaxPooling2D((2, 2))(x1)\n",
        "  x1 = Conv2D(256, (3, 3), activation='relu')(x1)\n",
        "  x1 = MaxPooling2D((2, 2))(x1)\n",
        "  x1 = Flatten()(x1)\n",
        "\n",
        "  x2 = Conv2D(64, (3, 3), activation='relu')(depth_input_2)\n",
        "  x2 = MaxPooling2D((2, 2))(x2)\n",
        "  x2 = Conv2D(128, (3, 3), activation='relu')(x2)\n",
        "  x2 = MaxPooling2D((2, 2))(x2)\n",
        "  x2 = Conv2D(256, (3, 3), activation='relu')(x2)\n",
        "  x2 = MaxPooling2D((2, 2))(x2)\n",
        "  x2 = Flatten()(x2)\n",
        "\n",
        "  # Concatene as saídas das camadas convolucionais\n",
        "  concatenated_output = Concatenate()([x1, x2])\n",
        "\n",
        "  x = Dense(256, activation='relu')(concatenated_output)\n",
        "\n",
        "  # Saída\n",
        "  output = Dense(len(campos), activation='linear')(x)\n",
        "\n",
        "  # Construa o modelo com as duas entradas\n",
        "  model = Model(inputs=[depth_input_1, depth_input_2], outputs=output)\n",
        "\n",
        "  # Compile o modelo\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "  return model\n",
        "\n",
        "inference_model = create_model()\n",
        "inference_model.load_weights(\"estimativa_de_peso_vivo_03.keras\")\n",
        "\n",
        "model = load_model(weights_path, device=device)\n",
        "model_seg = YOLO('yolov8s-seg.pt')\n",
        "\n",
        "# Carregando o CSV com os dados\n",
        "data = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Dicionário de tradução das saídas\n",
        "traducao = {\n",
        "    'live weithg': 'Peso Vivo',\n",
        "    'withers height': 'Altura da Cernelha',\n",
        "    'hip height': 'Altura do Quadril',\n",
        "    'chest depth': 'Profundidade do Peito',\n",
        "    'chest width': 'Largura do Peito',\n",
        "    'ilium width': 'Largura do Ílio',\n",
        "    'hip joint width': 'Largura da Articulação do Quadril',\n",
        "    'oblique body length': 'Comprimento do Corpo Oblíquo',\n",
        "    'hip length': 'Comprimento do Quadril',\n",
        "    'heart girth': 'Circunferência Torácica'\n",
        "}\n",
        "\n",
        "\n",
        "def get_depth(image):\n",
        "    depths = []\n",
        "    i = 1\n",
        "    cv2.imwrite('/content/dust3r/temp_img/1.png',image)\n",
        "    imgs = load_images('/content/dust3r/temp_img', size=512)\n",
        "    if len(imgs) == 1:\n",
        "        imgs = [imgs[0], copy.deepcopy(imgs[0])]\n",
        "        imgs[1]['idx'] = 1\n",
        "\n",
        "    scenegraph_type = f\"swin-1\"\n",
        "\n",
        "    pairs = make_pairs(imgs, scene_graph=scenegraph_type, prefilter=None, symmetrize=True)\n",
        "    output = inference(pairs, model, device)\n",
        "\n",
        "    mode = GlobalAlignerMode.PointCloudOptimizer if len(imgs) > 2 else GlobalAlignerMode.PairViewer\n",
        "    scene = global_aligner(output, device=device, mode=mode)\n",
        "\n",
        "    if mode == GlobalAlignerMode.PointCloudOptimizer:\n",
        "        loss = scene.compute_global_alignment(init='mst')\n",
        "\n",
        "    pts3d = to_numpy(scene.get_pts3d())\n",
        "\n",
        "    for pts in pts3d:\n",
        "      normalizedpts3d = cv2.normalize(pts,  pts, 0, 255, cv2.NORM_MINMAX)\n",
        "      one_channel_3d = cv2.cvtColor(normalizedpts3d, cv2.COLOR_BGR2GRAY)\n",
        "      depths.append(one_channel_3d)\n",
        "      print(f\"Imagem convertida {i}\")\n",
        "      i += 1\n",
        "    return depths\n",
        "\n",
        "def get_mask(image):\n",
        "  results = model_seg.predict(image.copy(), conf=0.40)\n",
        "  masks = results[0].masks\n",
        "  mask1 = masks.masks\n",
        "  mask = mask1.data.cpu().numpy()\n",
        "  mask = mask.squeeze()\n",
        "  return mask\n",
        "\n",
        "st.title(\"ENGORD.AI - BIOMETRIA \")\n",
        "uploaded_file = st.file_uploader(\"Faça o upload da imagem:\", type=['jpg', 'png'])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "  dim = 256\n",
        "  file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)\n",
        "  image = cv2.imdecode(file_bytes, 1)\n",
        "\n",
        "\n",
        "  with st.spinner('Realizando predições'):\n",
        "    col1, col2, col3, col4, col5 = st.columns(5)\n",
        "    col1.image(image, channels=\"BGR\")\n",
        "\n",
        "    depths = get_depth(image)\n",
        "    depth = depths[0]\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(depth)\n",
        "    col2.pyplot(fig)\n",
        "\n",
        "    mask = get_mask(image)\n",
        "    fig2, ax2 = plt.subplots()\n",
        "    ax2.imshow(mask)\n",
        "    mask = cv2.resize(mask,(dim,dim))\n",
        "\n",
        "    col2.pyplot(fig2)\n",
        "\n",
        "    resize_depth = cv2.resize(depth,(dim,dim))\n",
        "    norm_depth = resize_depth / 255.\n",
        "\n",
        "    depth_fim = np.expand_dims(norm_depth, axis=0)\n",
        "    mask_fim = np.expand_dims(mask, axis=0)\n",
        "    prediction = inference_model.predict([depth_fim, mask_fim])\n",
        "\n",
        "    col3.subheader('Estimativa')\n",
        "    predictions = []\n",
        "    try:\n",
        "        for i, campo in enumerate(traducao.keys()):\n",
        "            col3.markdown(f'<b>{traducao[campo]}</b>: {round(float(prediction[0][i]),2)}', unsafe_allow_html=True)\n",
        "            predictions.append(prediction[0][i])\n",
        "\n",
        "    except:\n",
        "        pass\n",
        "    col4.subheader('Dado Real')\n",
        "    col5.subheader('Precisão')\n",
        "    N = int(uploaded_file.name.split(\".\")[0])-1\n",
        "    precisao_total = []\n",
        "    for i,campo in enumerate(traducao.keys()):\n",
        "        if campo == \"N\" or 'time' in campo or 'Data' in campo:\n",
        "            continue\n",
        "        col4.markdown(f'<b>{traducao[campo]}</b>: {data.iloc[N][campo]}', unsafe_allow_html=True)\n",
        "        v = float(data.iloc[N][campo])\n",
        "        p = predictions[i]\n",
        "        per = v/ 100\n",
        "        diff = abs(v-p)\n",
        "        percent = 100 - (diff/per)\n",
        "        precisao_total.append(percent)\n",
        "        col5.markdown(f'{round(percent,2)}%', unsafe_allow_html=True)\n",
        "    precisao_modelo = sum(precisao_total)/len(precisao_total)\n",
        "    col4.subheader(f\"Precisão do Modelo: {round(precisao_modelo,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZDFRYU_Kjp9"
      },
      "outputs": [],
      "source": [
        "%cd /content/dust3r"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "CPAjPxltyjYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vjEj6G2DAZH"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZ7s25r7DCXq"
      },
      "outputs": [],
      "source": [
        "!npx localtunnel --port 8504"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXFHqE_vOLWO"
      },
      "source": [
        "## **DEMO DUST3R**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLxh529lg-JH"
      },
      "outputs": [],
      "source": [
        "%cd /content/dust3r/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lg1z3_XRIz5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "628dfc1a-0acf-4425-eeeb-f3bd2361fe71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... loading model from /content/dust3r/checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\n",
            "instantiating : AsymmetricCroCo3DStereo(enc_depth=24, dec_depth=12, enc_embed_dim=1024, dec_embed_dim=768, enc_num_heads=16, dec_num_heads=12, pos_embed='RoPE100', patch_embed_cls='PatchEmbedDust3R', img_size=(512, 512), head_type='dpt', output_mode='pts3d', depth_mode=('exp', -inf, inf), conf_mode=('exp', 1, inf), landscape_only=False)\n",
            "<All keys matched successfully>\n",
            "Outputing stuff in /tmp/tmpoxgsdxf4dust3r_gradio_demo\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://6a8f9627340a3881cf.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 527, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 261, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1786, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1338, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 759, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/dust3r/demo.py\", line 123, in get_reconstructed_scene\n",
            "    imgs = load_images(filelist, size=image_size)\n",
            "  File \"/content/dust3r/dust3r/utils/image.py\", line 80, in load_images\n",
            "    raise ValueError(f'bad {folder_or_list=} ({type(folder_or_list)})')\n",
            "ValueError: bad folder_or_list=None (<class 'NoneType'>)\n",
            ">> Loading a list of 26 images\n",
            " - adding /tmp/gradio/8a7ab81832031b06ce273dc5d2faf30029b33201/IMG-20240416-WA0007.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/0cf3593db8de3a00f67e66c795781afe87c0fb3a/IMG-20240416-WA0008.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/44b6d1ad4efacb8b73b3f2d0b06ca418318be081/IMG-20240416-WA0009.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/4a193148ac8417149cdac78c3007cf452e230aef/IMG-20240416-WA0010.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/8b0a50fd72e0ddcbe1e9b2e1e79302eee2ccd23c/IMG-20240416-WA0012.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/3584b65494e0a32b791423c492c8deef8e0e1192/IMG-20240416-WA0013.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/8ed5189d1f816731e90d70c4223a00c87bc0fc96/IMG-20240416-WA0016.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/b7526cad720e5acc337ee70d707e0369f3f454a9/IMG-20240416-WA0017.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/cc10619037df024ebb3a2c8495c6b4b3ff17a558/IMG-20240416-WA0018.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/ed48f8bf53674caf09b1a323ea4ac05910ec55de/IMG-20240416-WA0019.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/19ef8c163ed1140f739a0ffa6efbbc6f73c777d4/IMG-20240416-WA0020.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/1beaa8bdef995bc13626c3f037c6f913acd32ffc/IMG-20240416-WA0021.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/122d13d943899aa9d26ab894be7c916fdf0d3369/IMG-20240416-WA0022.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/ef5778a6849545658e7f6675415f3e28d31f7fac/IMG-20240416-WA0023.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/3df01a25f447bd204a1035700ca209ccebbb6978/IMG-20240416-WA0024.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/7643880f875f37ce18731ecb8cda50c0a68b28f4/IMG-20240416-WA0025.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/5faee5080a1975656043470b64fe69c83cf578e8/IMG-20240416-WA0026.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/e28e6e8b360da9347622fcdd3a66d1d06c1f42b1/IMG-20240416-WA0027.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/576ab35708ccd1e6faff43ec3553b19fb2a5d8ab/IMG-20240416-WA0028.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/aea9fd509aa3f710e202170d5af750724fbd2744/IMG-20240416-WA0029.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/eb510d0560a6982db3d41d44d0e36927a3e2e20d/IMG-20240416-WA0030.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/4af9e14250d7b635fd5e8ebea0f3621fd56208cf/IMG-20240416-WA0031.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/4cdc77b313c04f151009692521557c735b702f74/IMG-20240416-WA0032.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/cfe3e5f98a18dc1c9275b41b28b002a068611985/IMG-20240416-WA0033.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/44d30e2be717ebfab87be8556a2e430a53a03140/IMG-20240416-WA0034.jpg with resolution 1600x1200 --> 512x384\n",
            " - adding /tmp/gradio/625dcd59a526c1778df7b7a54bf85b684573e47d/IMG-20240416-WA0035.jpg with resolution 1600x1200 --> 512x384\n",
            " (Found 26 images)\n",
            ">> Inference with model on 650 image pairs\n",
            "100% 650/650 [07:20<00:00,  1.48it/s]\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python3 demo.py --weights /content/dust3r/checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qda1QwD5JhXg",
        "ghMCcpSfCwUu"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}